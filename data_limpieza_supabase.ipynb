{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82995402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied uber/data/productos_completo.jsonl -> uber/data/raw_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "src = Path(\"uber/data/productos_completo.jsonl\")\n",
    "dst = src.with_name(\"raw_data.jsonl\")\n",
    "\n",
    "if not src.exists():\n",
    "    raise FileNotFoundError(f\"Source file not found: {src}\")\n",
    "\n",
    "shutil.copy2(src, dst)\n",
    "print(f\"Copied {src} -> {dst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6f1344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nService links:\\n- Uber Eats: its contained in the raw data jsonl file for each restaurant\\n- Rappi: https://www.rappi.cl/restaurantes\\n- PedidosYa: https://www.pedidosya.cl/restaurantes?bt=RESTAURANT&origin=home&lat=-33.44889&lng=-70.669266&areaId=16977&areaName=Santiago%20Centro&address=Santiago\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Table: restaurants\n",
    "\n",
    "Name,Format,Type\n",
    "id,bigint,number\n",
    "name,text,string\n",
    "service,text,string\n",
    "latitude,double precision,number\n",
    "longitude,double precision,number\n",
    "address,text,string\n",
    "zone,text,string\n",
    "service_link,text,string\n",
    "image,text,string\n",
    "created_at,timestamp with time zone,string\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Table: food_items\n",
    "\n",
    "Name,Format,Type\n",
    "id,bigint,number\n",
    "restaurant,text,string\n",
    "food,text,string\n",
    "price,text,string\n",
    "service,text,string\n",
    "image,text,string\n",
    "service_link,text,string\n",
    "restaurant_id,bigint,number\n",
    "category,text,string\n",
    "description,text,string\n",
    "created_at,timestamp with time zone,string\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Services: \n",
    "- Uber Eats\n",
    "- Rappi\n",
    "- PedidosYa\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Service links:\n",
    "- Uber Eats: its contained in the raw data jsonl file for each restaurant\n",
    "- Rappi: https://www.rappi.cl/restaurantes\n",
    "- PedidosYa: https://www.pedidosya.cl/restaurantes?bt=RESTAURANT&origin=home&lat=-33.44889&lng=-70.669266&areaId=16977&areaName=Santiago%20Centro&address=Santiago\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2356b0e",
   "metadata": {},
   "source": [
    "Data mapping from `raw_data.jsonl` to Supabase tables:\n",
    "\n",
    "- **restaurants.name** â†’ JSON `name`\n",
    "- **restaurants.service** â†’ duplicated per service (`Uber Eats`, `Rappi`, `PedidosYa`)\n",
    "- **restaurants.latitude** / **longitude** â†’ JSON `geo.latitude` and `geo.longitude`\n",
    "- **restaurants.address** â†’ JSON `address.streetAddress`\n",
    "- **restaurants.zone** â†’ JSON `address.addressLocality` (fallback to `address.addressRegion`)\n",
    "- **restaurants.service_link** â†’ `restaurant_url` for Uber Eats, static homepages for the other services\n",
    "- **restaurants.image** â†’ first URL in JSON `image` array\n",
    "\n",
    "- **food_items.restaurant** â†’ JSON `name`\n",
    "- **food_items.food** â†’ menu item `name`\n",
    "- **food_items.price** â†’ `offers.price` (with `priceCurrency` appended when available)\n",
    "- **food_items.category** â†’ menu section `name`\n",
    "- **food_items.description** â†’ menu item `description`\n",
    "- **food_items.service_link** and **service** â†’ mirror parent restaurant entry\n",
    "- **food_items.restaurant_id** â†’ numeric id assigned to the matching restaurant row\n",
    "- **created_at** columns â†’ populated during export with the current UTC timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65648459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1000 restaurants from 5904 candidates.\n",
      "Removed 6861 duplicate food items.\n",
      "Exported 3000 restaurant rows to /Users/ffontecilla/Desktop/GPTI/food-scraper-santiago/supabase_update/restaurants.csv\n",
      "Exported 179784 food item rows to /Users/ffontecilla/Desktop/GPTI/food-scraper-santiago/supabase_update/food_items.csv\n",
      "Exported 3000 restaurant rows to /Users/ffontecilla/Desktop/GPTI/food-scraper-santiago/supabase_update/restaurants.csv\n",
      "Exported 179784 food item rows to /Users/ffontecilla/Desktop/GPTI/food-scraper-santiago/supabase_update/food_items.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DATA_PATH = Path(\"uber/data/raw_data.jsonl\")\n",
    "OUTPUT_DIR = Path(\"supabase_update\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_RESTAURANTS = OUTPUT_DIR / \"restaurants.csv\"\n",
    "OUTPUT_FOOD_ITEMS = OUTPUT_DIR / \"food_items.csv\"\n",
    "\n",
    "SERVICE_LINKS = {\n",
    "    \"Uber Eats\": lambda link: link or \"\",\n",
    "    \"Rappi\": lambda _link: \"https://www.rappi.cl/restaurantes\",\n",
    "    \"PedidosYa\": lambda _link: (\n",
    "        \"https://www.pedidosya.cl/restaurantes?bt=RESTAURANT&origin=home\"\n",
    "        \"&lat=-33.44889&lng=-70.669266&areaId=16977&areaName=Santiago%20Centro&address=Santiago\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "UNUSUAL_TERMINATORS = (\"\\u2028\", \"\\u2029\", \"\\r\", \"\\n\")\n",
    "SAMPLE_RESTAURANT_COUNT = 1000\n",
    "SAMPLE_RANDOM_SEED = 12345\n",
    "\n",
    "def ensure_list(value: Any) -> List[Any]:\n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if value is None:\n",
    "        return []\n",
    "    return [value]\n",
    "\n",
    "def safe_float(value: Any) -> Optional[float]:\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "def sanitize_text(value: Any) -> str:\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "    text = str(value)\n",
    "    for token in UNUSUAL_TERMINATORS:\n",
    "        text = text.replace(token, \" \")\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def normalize_price(value: Any) -> str:\n",
    "    text = sanitize_text(value)\n",
    "    if \".\" in text:\n",
    "        text = text.split(\".\", 1)[0]\n",
    "    digits = \"\".join(ch for ch in text if ch.isdigit())\n",
    "    if not digits:\n",
    "        return \"\"\n",
    "    return str(int(digits))\n",
    "\n",
    "def has_unusual_terminator(line: str) -> bool:\n",
    "    if not line:\n",
    "        return False\n",
    "    return line.endswith(\"\\r\") and not line.endswith(\"\\r\\n\")\n",
    "\n",
    "restaurant_payloads: List[Dict[str, Any]] = []\n",
    "timestamp = datetime.now(timezone.utc).replace(microsecond=0).isoformat()\n",
    "skipped_terminator = 0\n",
    "\n",
    "with RAW_DATA_PATH.open(\"r\", encoding=\"utf-8\", newline=\"\") as handle:\n",
    "    for line_no, raw_line in enumerate(handle, start=1):\n",
    "        if has_unusual_terminator(raw_line):\n",
    "            skipped_terminator += 1\n",
    "            continue\n",
    "\n",
    "        stripped = raw_line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "        try:\n",
    "            payload = json.loads(stripped)\n",
    "        except json.JSONDecodeError as exc:\n",
    "            raise ValueError(f\"Invalid JSON on line {line_no}: {exc}\") from exc\n",
    "\n",
    "        name = sanitize_text(payload.get(\"name\"))\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        geo = payload.get(\"geo\") or {}\n",
    "        address_data = payload.get(\"address\") or {}\n",
    "\n",
    "        base_service_link = sanitize_text(payload.get(\"restaurant_url\") or payload.get(\"@id\") or \"\")\n",
    "        latitude = safe_float(geo.get(\"latitude\"))\n",
    "        longitude = safe_float(geo.get(\"longitude\"))\n",
    "        address = sanitize_text(address_data.get(\"streetAddress\"))\n",
    "        zone = sanitize_text(address_data.get(\"addressLocality\") or address_data.get(\"addressRegion\"))\n",
    "\n",
    "        menu = payload.get(\"hasMenu\") or {}\n",
    "        sections = ensure_list(menu.get(\"hasMenuSection\") or [])\n",
    "\n",
    "        processed_sections: List[Dict[str, Any]] = []\n",
    "        for section in sections:\n",
    "            if not isinstance(section, dict):\n",
    "                continue\n",
    "            category = sanitize_text(section.get(\"name\"))\n",
    "            items = ensure_list(section.get(\"hasMenuItem\"))\n",
    "\n",
    "            processed_items: List[Dict[str, str]] = []\n",
    "            for item in items:\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                offers = item.get(\"offers\") or {}\n",
    "                if isinstance(offers, list):\n",
    "                    offers = offers[0] if offers else {}\n",
    "\n",
    "                price_value = offers.get(\"price\") if isinstance(offers, dict) else \"\"\n",
    "                processed_items.append({\n",
    "                    \"food\": sanitize_text(item.get(\"name\")),\n",
    "                    \"price\": normalize_price(price_value),\n",
    "                    \"description\": sanitize_text(item.get(\"description\")),\n",
    "                })\n",
    "\n",
    "            processed_sections.append({\n",
    "                \"category\": category,\n",
    "                \"items\": processed_items,\n",
    "            })\n",
    "\n",
    "        restaurant_payloads.append({\n",
    "            \"name\": name,\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"address\": address,\n",
    "            \"zone\": zone,\n",
    "            \"service_link\": base_service_link,\n",
    "            \"sections\": processed_sections,\n",
    "        })\n",
    "\n",
    "total_candidates = len(restaurant_payloads)\n",
    "if total_candidates == 0:\n",
    "    restaurants_df = pd.DataFrame(columns=[\"id\",\"name\",\"service\",\"latitude\",\"longitude\",\"address\",\"zone\",\"service_link\",\"created_at\"])\n",
    "    food_items_df = pd.DataFrame(columns=[\"id\",\"restaurant\",\"food\",\"price\",\"service\",\"service_link\",\"restaurant_id\",\"category\",\"description\",\"created_at\"])\n",
    "else:\n",
    "    rng = random.Random(SAMPLE_RANDOM_SEED)\n",
    "    sample_size = min(SAMPLE_RESTAURANT_COUNT, total_candidates)\n",
    "    sampled_indices = sorted(rng.sample(range(total_candidates), sample_size)) if sample_size < total_candidates else list(range(total_candidates))\n",
    "    sampled_payloads = [restaurant_payloads[index] for index in sampled_indices]\n",
    "\n",
    "    restaurants_rows: List[Dict[str, Any]] = []\n",
    "    food_items_rows: List[Dict[str, Any]] = []\n",
    "    restaurant_id = 1\n",
    "    food_item_id = 1\n",
    "\n",
    "    for payload in sampled_payloads:\n",
    "        for service, link_builder in SERVICE_LINKS.items():\n",
    "            current_restaurant_id = restaurant_id\n",
    "            service_link = sanitize_text(link_builder(payload[\"service_link\"]))\n",
    "\n",
    "            restaurants_rows.append({\n",
    "                \"id\": current_restaurant_id,\n",
    "                \"name\": payload[\"name\"],\n",
    "                \"service\": service,\n",
    "                \"latitude\": payload[\"latitude\"],\n",
    "                \"longitude\": payload[\"longitude\"],\n",
    "                \"address\": payload[\"address\"],\n",
    "                \"zone\": payload[\"zone\"],\n",
    "                \"service_link\": service_link,\n",
    "                \"created_at\": timestamp,\n",
    "            })\n",
    "\n",
    "            for section in payload[\"sections\"]:\n",
    "                category = section[\"category\"]\n",
    "                for item in section[\"items\"]:\n",
    "                    food_items_rows.append({\n",
    "                        \"id\": food_item_id,\n",
    "                        \"restaurant\": payload[\"name\"],\n",
    "                        \"food\": item[\"food\"],\n",
    "                        \"price\": item[\"price\"],\n",
    "                        \"service\": service,\n",
    "                        \"service_link\": service_link,\n",
    "                        \"restaurant_id\": current_restaurant_id,\n",
    "                        \"category\": category,\n",
    "                        \"description\": item[\"description\"],\n",
    "                        \"created_at\": timestamp,\n",
    "                    })\n",
    "                    food_item_id += 1\n",
    "\n",
    "            restaurant_id += 1\n",
    "\n",
    "    restaurants_df = pd.DataFrame(\n",
    "        restaurants_rows,\n",
    "        columns=[\n",
    "            \"id\",\n",
    "            \"name\",\n",
    "            \"service\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"address\",\n",
    "            \"zone\",\n",
    "            \"service_link\",\n",
    "            \"created_at\",\n",
    "        ],\n",
    "    )\n",
    "    food_items_df = pd.DataFrame(\n",
    "        food_items_rows,\n",
    "        columns=[\n",
    "            \"id\",\n",
    "            \"restaurant\",\n",
    "            \"food\",\n",
    "            \"price\",\n",
    "            \"service\",\n",
    "            \"service_link\",\n",
    "            \"restaurant_id\",\n",
    "            \"category\",\n",
    "            \"description\",\n",
    "            \"created_at\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(f\"Sampled {len(sampled_payloads)} restaurants from {total_candidates} candidates.\")\n",
    "\n",
    "    # Drop duplicate food items that only differ by internal id or category.\n",
    "    dedupe_subset = [column for column in food_items_df.columns if column not in {\"id\", \"category\"}]\n",
    "    before_dedup = len(food_items_df)\n",
    "    food_items_df = food_items_df.drop_duplicates(subset=dedupe_subset, keep=\"first\").reset_index(drop=True)\n",
    "    if len(food_items_df) != before_dedup:\n",
    "        food_items_df[\"id\"] = range(1, len(food_items_df) + 1)\n",
    "        print(f\"Removed {before_dedup - len(food_items_df)} duplicate food items.\")\n",
    "\n",
    "restaurants_df.to_csv(OUTPUT_RESTAURANTS, index=False)\n",
    "food_items_df.to_csv(OUTPUT_FOOD_ITEMS, index=False)\n",
    "\n",
    "print(f\"Exported {len(restaurants_df)} restaurant rows to {OUTPUT_RESTAURANTS.resolve()}\")\n",
    "print(f\"Exported {len(food_items_df)} food item rows to {OUTPUT_FOOD_ITEMS.resolve()}\")\n",
    "if skipped_terminator:\n",
    "    print(f\"Skipped {skipped_terminator} lines due to unusual line terminators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed43a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived 3917 unique categories from food items.\n",
      "Sample emoji mappings:\n",
      "  ðŸ½ï¸ (Envuelto en Palta) 10 pzas\n",
      "  ðŸŸ (Envuelto en SalmÃ³n) 10 pzas\n",
      "  ðŸ½ï¸ *Cachapas ðŸ‡»ðŸ‡ª (Variedades)*\n",
      "  ðŸ½ï¸ + Waffles by Buffalo Waffles\n",
      "  ðŸ½ï¸ +AcompaÃ±amientos\n",
      "  ðŸ¥¤ +Bebestibles\n",
      "  ðŸª +Galletas by Buffalo Waffles\n",
      "  ðŸ½ï¸ +Milanesas Grandes\n",
      "  ðŸ½ï¸ +Milanesas Individuales\n",
      "  ðŸ½ï¸ +Promos\n",
      "Updated CSV exports with emoji-backed image columns.\n",
      "Updated CSV exports with emoji-backed image columns.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "DEFAULT_EMOJI = \"ðŸ½ï¸\"\n",
    "KEYWORD_TO_EMOJI = {\n",
    "    \"pizza\": \"ðŸ•\",\n",
    "    \"pasta\": \"ðŸ\",\n",
    "    \"lasana\": \"ðŸ\",\n",
    "    \"noodle\": \"ðŸœ\",\n",
    "    \"ramen\": \"ðŸœ\",\n",
    "    \"sopa\": \"ðŸ²\",\n",
    "    \"soup\": \"ðŸ²\",\n",
    "    \"arroz\": \"ðŸš\",\n",
    "    \"rice\": \"ðŸš\",\n",
    "    \"curry\": \"ðŸ›\",\n",
    "    \"sandwich\": \"ðŸ¥ª\",\n",
    "    \"panini\": \"ðŸ¥ª\",\n",
    "    \"wrap\": \"ðŸŒ¯\",\n",
    "    \"taco\": \"ðŸŒ®\",\n",
    "    \"tacos\": \"ðŸŒ®\",\n",
    "    \"burrito\": \"ðŸŒ¯\",\n",
    "    \"empanada\": \"ðŸ¥Ÿ\",\n",
    "    \"queso\": \"ðŸ§€\",\n",
    "    \"bife\": \"ðŸ¥©\",\n",
    "    \"steak\": \"ðŸ¥©\",\n",
    "    \"carne\": \"ðŸ¥©\",\n",
    "    \"beef\": \"ðŸ¥©\",\n",
    "    \"churrasco\": \"ðŸ¥©\",\n",
    "    \"burger\": \"ðŸ”\",\n",
    "    \"hamburguesa\": \"ðŸ”\",\n",
    "    \"pollo\": \"ðŸ—\",\n",
    "    \"chicken\": \"ðŸ—\",\n",
    "    \"cerdo\": \"ðŸ¥“\",\n",
    "    \"res\": \"ðŸ¥©\",\n",
    "    \"pescado\": \"ðŸŸ\",\n",
    "    \"marisco\": \"ðŸ¦ž\",\n",
    "    \"camaron\": \"ðŸ¦\",\n",
    "    \"salmon\": \"ðŸŸ\",\n",
    "    \"ensalada\": \"ðŸ¥—\",\n",
    "    \"salad\": \"ðŸ¥—\",\n",
    "    \"vegano\": \"ðŸ¥¬\",\n",
    "    \"vegetariano\": \"ðŸ¥¦\",\n",
    "    \"veggie\": \"ðŸ¥¦\",\n",
    "    \"sushi\": \"ðŸ£\",\n",
    "    \"roll\": \"ðŸ£\",\n",
    "    \"gohan\": \"ðŸ±\",\n",
    "    \"combo\": \"ðŸ±\",\n",
    "    \"postre\": \"ðŸ°\",\n",
    "    \"dessert\": \"ðŸ°\",\n",
    "    \"torta\": \"ðŸ°\",\n",
    "    \"cake\": \"ðŸ°\",\n",
    "    \"kuchen\": \"ðŸ¥§\",\n",
    "    \"pie\": \"ðŸ¥§\",\n",
    "    \"galleta\": \"ðŸª\",\n",
    "    \"cookie\": \"ðŸª\",\n",
    "    \"brownie\": \"ðŸ«\",\n",
    "    \"helado\": \"ðŸ¨\",\n",
    "    \"ice\": \"ðŸ¨\",\n",
    "    \"bebida\": \"ðŸ¥¤\",\n",
    "    \"bebestible\": \"ðŸ¥¤\",\n",
    "    \"drink\": \"ðŸ¥¤\",\n",
    "    \"jugo\": \"ðŸ§ƒ\",\n",
    "    \"juice\": \"ðŸ§ƒ\",\n",
    "    \"coffee\": \"â˜•\",\n",
    "    \"cafe\": \"â˜•\",\n",
    "    \"te\": \"ðŸµ\",\n",
    "    \"desayuno\": \"ðŸ³\",\n",
    "    \"breakfast\": \"ðŸ³\",\n",
    "    \"snack\": \"ðŸ¿\",\n",
    "    \"kids\": \"ðŸ§’\",\n",
    "    \"nino\": \"ðŸ§’\",\n",
    "    \"dulce\": \"ðŸ¬\",\n",
    "    \"bakery\": \"ðŸ¥\",\n",
    "}\n",
    "TOKEN_PATTERN = re.compile(r\"[\\w']+\")\n",
    "\n",
    "def ascii_tokens(text: str) -> List[str]:\n",
    "    sanitized = sanitize_text(text)\n",
    "    normalized = unicodedata.normalize(\"NFKD\", sanitized)\n",
    "    ascii_text = \"\".join(ch for ch in normalized if not unicodedata.combining(ch))\n",
    "    return [token.lower() for token in TOKEN_PATTERN.findall(ascii_text)]\n",
    "\n",
    "unique_categories = sorted({cat for cat in food_items_df[\"category\"] if cat})\n",
    "print(f\"Derived {len(unique_categories)} unique categories from food items.\")\n",
    "\n",
    "emoji_mapping = {}\n",
    "for category in unique_categories:\n",
    "    tokens = ascii_tokens(category)\n",
    "    chosen = DEFAULT_EMOJI\n",
    "    for token in tokens:\n",
    "        if token in KEYWORD_TO_EMOJI:\n",
    "            chosen = KEYWORD_TO_EMOJI[token]\n",
    "            break\n",
    "        if token.endswith(\"s\") and token[:-1] in KEYWORD_TO_EMOJI:\n",
    "            chosen = KEYWORD_TO_EMOJI[token[:-1]]\n",
    "            break\n",
    "    emoji_mapping[category] = chosen\n",
    "\n",
    "sample_preview = list(emoji_mapping.items())[:10]\n",
    "if sample_preview:\n",
    "    print(\"Sample emoji mappings:\")\n",
    "    for category, emoji in sample_preview:\n",
    "        print(f\"  {emoji} {category}\")\n",
    "\n",
    "food_items_df[\"image\"] = food_items_df[\"category\"].map(lambda cat: emoji_mapping.get(cat, DEFAULT_EMOJI))\n",
    "\n",
    "restaurant_emoji = (\n",
    "    food_items_df.groupby(\"restaurant_id\")[\"image\"].agg(\n",
    "        lambda series: series.mode().iat[0] if not series.mode().empty else DEFAULT_EMOJI\n",
    "    )\n",
    ").to_dict()\n",
    "\n",
    "restaurants_df[\"image\"] = restaurants_df[\"id\"].map(restaurant_emoji).fillna(DEFAULT_EMOJI)\n",
    "restaurant_image_map = restaurants_df.set_index(\"id\")[\"image\"].to_dict()\n",
    "\n",
    "default_mask = food_items_df[\"image\"] == DEFAULT_EMOJI\n",
    "if default_mask.any():\n",
    "    fallback = food_items_df.loc[default_mask, \"restaurant_id\"].map(restaurant_image_map)\n",
    "    fallback = fallback.mask(fallback == DEFAULT_EMOJI)\n",
    "    food_items_df.loc[default_mask, \"image\"] = fallback.fillna(DEFAULT_EMOJI)\n",
    "\n",
    "restaurants_df = restaurants_df[[\n",
    "    \"id\",\n",
    "    \"name\",\n",
    "    \"service\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"address\",\n",
    "    \"zone\",\n",
    "    \"service_link\",\n",
    "    \"image\",\n",
    "    \"created_at\",\n",
    " ]]\n",
    "food_items_df = food_items_df[[\n",
    "    \"id\",\n",
    "    \"restaurant\",\n",
    "    \"food\",\n",
    "    \"price\",\n",
    "    \"service\",\n",
    "    \"image\",\n",
    "    \"service_link\",\n",
    "    \"restaurant_id\",\n",
    "    \"category\",\n",
    "    \"description\",\n",
    "    \"created_at\",\n",
    " ]]\n",
    "\n",
    "restaurants_df.to_csv(OUTPUT_RESTAURANTS, index=False)\n",
    "food_items_df.to_csv(OUTPUT_FOOD_ITEMS, index=False)\n",
    "\n",
    "print(\"Updated CSV exports with emoji-backed image columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b4c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted prices for 59928 food items across Rappi and PedidosYa.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def parse_price(value: str) -> Optional[int]:\n",
    "    if not value:\n",
    "        return None\n",
    "    digits = ''.join(ch for ch in value if ch.isdigit())\n",
    "    if not digits:\n",
    "        return None\n",
    "    return int(digits)\n",
    "\n",
    "def format_price(amount: Optional[int]) -> str:\n",
    "    if amount is None:\n",
    "        return \"\"\n",
    "    return str(amount)\n",
    "\n",
    "ADJUSTABLE_SERVICES = {\"Rappi\", \"PedidosYa\"}\n",
    "ALLOWED_DELTAS = [amount for amount in range(100, 3001, 100)]\n",
    "SAMPLE_FRACTION = 0.5\n",
    "\n",
    "mask_services = food_items_df[\"service\"].isin(ADJUSTABLE_SERVICES)\n",
    "mask_has_price = food_items_df[\"price\"].apply(parse_price).notna()\n",
    "eligible_mask = mask_services & mask_has_price\n",
    "eligible_indices = food_items_df.index[eligible_mask]\n",
    "\n",
    "random.seed(42)\n",
    "selected_count = int(len(eligible_indices) * SAMPLE_FRACTION)\n",
    "selected_indices = random.sample(list(eligible_indices), k=selected_count) if selected_count else []\n",
    "\n",
    "adjusted_count = 0\n",
    "for idx in selected_indices:\n",
    "    current_price = parse_price(food_items_df.at[idx, \"price\"])\n",
    "    if current_price is None:\n",
    "        continue\n",
    "    delta = random.choice(ALLOWED_DELTAS)\n",
    "    sign = random.choice([-1, 1])\n",
    "    new_price = max(current_price + sign * delta, ALLOWED_DELTAS[0])\n",
    "    food_items_df.at[idx, \"price\"] = format_price(new_price)\n",
    "    adjusted_count += 1\n",
    "\n",
    "if adjusted_count:\n",
    "    restaurants_df.to_csv(OUTPUT_RESTAURANTS, index=False)\n",
    "    food_items_df.to_csv(OUTPUT_FOOD_ITEMS, index=False)\n",
    "    print(f\"Adjusted prices for {adjusted_count} food items across Rappi and PedidosYa.\")\n",
    "else:\n",
    "    print(\"No eligible food items found for price adjustments.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
